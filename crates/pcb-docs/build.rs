use regex::Regex;
use std::collections::HashMap;
use std::env;
use std::fs;
use std::path::Path;
use walkdir::WalkDir;

fn main() {
    let out_dir = env::var("OUT_DIR").unwrap();
    let manifest_dir = env::var("CARGO_MANIFEST_DIR").unwrap();

    // docs/pages is at the workspace root, two levels up from this crate
    let docs_dir = Path::new(&manifest_dir).join("../../docs/pages");

    println!("cargo:rerun-if-changed={}", docs_dir.display());

    let mut pages = Vec::new();
    let mut sections = Vec::new();

    for entry in WalkDir::new(&docs_dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| {
            e.path()
                .extension()
                .map(|ext| ext == "mdx")
                .unwrap_or(false)
        })
    {
        let path = entry.path();
        println!("cargo:rerun-if-changed={}", path.display());

        let content = fs::read_to_string(path).expect("Failed to read MDX file");
        let slug = path.file_stem().unwrap().to_string_lossy().to_string();

        let (frontmatter, body) = parse_frontmatter(&content);
        let title = frontmatter
            .get("title")
            .cloned()
            .unwrap_or_else(|| slug.clone());
        let description = frontmatter.get("description").cloned().unwrap_or_default();

        let markdown = convert_mdx_to_markdown(&body, &title, &description);

        // Extract sections
        let page_sections = extract_sections(&slug, &markdown);
        sections.extend(page_sections);

        pages.push((slug, title, description, markdown));
    }

    // Sort pages by slug for consistent ordering
    pages.sort_by(|a, b| a.0.cmp(&b.0));

    // Generate Rust source
    let mut output = String::new();
    output.push_str("// Auto-generated by build.rs - do not edit\n\n");

    // Page struct
    output.push_str(
        r#"#[derive(Debug, Clone)]
pub struct Page {
    pub slug: &'static str,
    pub title: &'static str,
    pub description: &'static str,
    pub markdown: &'static str,
}

#[derive(Debug, Clone)]
pub struct Section {
    pub page_slug: &'static str,
    pub section_id: &'static str,
    pub title: &'static str,
    pub level: u8,
    pub start: usize,
    pub end: usize,
}

"#,
    );

    // Generate PAGES array
    output.push_str("pub static PAGES: &[Page] = &[\n");
    for (slug, title, description, markdown) in &pages {
        output.push_str(&format!(
            "    Page {{\n        slug: {:?},\n        title: {:?},\n        description: {:?},\n        markdown: r####\"{}\"####,\n    }},\n",
            slug, title, description, markdown
        ));
    }
    output.push_str("];\n\n");

    // Generate SECTIONS array
    output.push_str("pub static SECTIONS: &[Section] = &[\n");
    for section in &sections {
        output.push_str(&format!(
            "    Section {{\n        page_slug: {:?},\n        section_id: {:?},\n        title: {:?},\n        level: {},\n        start: {},\n        end: {},\n    }},\n",
            section.page_slug, section.section_id, section.title, section.level, section.start, section.end
        ));
    }
    output.push_str("];\n");

    let dest_path = Path::new(&out_dir).join("docs_index.rs");
    fs::write(&dest_path, output).expect("Failed to write docs_index.rs");
}

fn parse_frontmatter(content: &str) -> (HashMap<String, String>, String) {
    let mut frontmatter = HashMap::new();

    if !content.starts_with("---") {
        return (frontmatter, content.to_string());
    }

    let parts: Vec<&str> = content.splitn(3, "---").collect();
    if parts.len() < 3 {
        return (frontmatter, content.to_string());
    }

    // Parse YAML-like frontmatter (simple key: "value" parsing)
    for line in parts[1].lines() {
        let line = line.trim();
        if line.is_empty() {
            continue;
        }
        if let Some((key, value)) = line.split_once(':') {
            let key = key.trim().to_string();
            let value = value.trim().trim_matches('"').to_string();
            frontmatter.insert(key, value);
        }
    }

    (frontmatter, parts[2].trim_start().to_string())
}

fn convert_mdx_to_markdown(content: &str, _title: &str, _description: &str) -> String {
    let mut result = content.to_string();

    // Convert callout components: <Info>, <Warning>, <Tip>, <Note>
    let callout_re =
        Regex::new(r"(?s)<(Info|Warning|Tip|Note)>\s*(.*?)\s*</(Info|Warning|Tip|Note)>").unwrap();
    result = callout_re
        .replace_all(&result, |caps: &regex::Captures| {
            let tag = &caps[1];
            let content = &caps[2];
            let quoted = content
                .lines()
                .map(|line| format!("> {}", line))
                .collect::<Vec<_>>()
                .join("\n");
            format!("> **{}**\n>\n{}", tag, quoted)
        })
        .to_string();

    // Convert <Accordion title="..."> to ### heading
    let accordion_re =
        Regex::new(r#"(?s)<Accordion\s+title="([^"]*)">\s*(.*?)\s*</Accordion>"#).unwrap();
    result = accordion_re
        .replace_all(&result, |caps: &regex::Captures| {
            let title = &caps[1];
            let content = &caps[2];
            format!("### {}\n\n{}", title, content)
        })
        .to_string();

    // Strip <CodeGroup> tags but keep content
    let codegroup_open_re = Regex::new(r"<CodeGroup>\s*").unwrap();
    let codegroup_close_re = Regex::new(r"\s*</CodeGroup>").unwrap();
    result = codegroup_open_re.replace_all(&result, "").to_string();
    result = codegroup_close_re.replace_all(&result, "").to_string();

    // Convert code fence titles: ```ts title="TypeScript" -> **TypeScript**\n\n```ts
    let code_title_re = Regex::new(r#"```(\w+)\s+(\w+)\s*\n"#).unwrap();
    result = code_title_re
        .replace_all(&result, |caps: &regex::Captures| {
            let lang = &caps[1];
            let title = &caps[2];
            format!("**{}**\n\n```{}\n", title, lang)
        })
        .to_string();

    // Convert <img> tags to markdown images
    let img_re =
        Regex::new(r#"<img\s+[^>]*src="([^"]*)"[^>]*(?:alt="([^"]*)")?[^>]*/?\s*>"#).unwrap();
    result = img_re
        .replace_all(&result, |caps: &regex::Captures| {
            let src = &caps[1];
            let alt = caps.get(2).map(|m| m.as_str()).unwrap_or("");
            format!("![{}]({})", alt, src)
        })
        .to_string();

    // Also handle alt before src
    let img_re2 = Regex::new(r#"<img\s+[^>]*alt="([^"]*)"[^>]*src="([^"]*)"[^>]*/?\s*>"#).unwrap();
    result = img_re2
        .replace_all(&result, |caps: &regex::Captures| {
            let alt = &caps[1];
            let src = &caps[2];
            format!("![{}]({})", alt, src)
        })
        .to_string();

    // Strip remaining img tags with className etc
    let img_generic_re = Regex::new(r#"<img\s+[^>]*/?\s*>"#).unwrap();
    result = img_generic_re.replace_all(&result, "").to_string();

    // Strip unknown self-closing JSX tags
    let self_closing_re = Regex::new(r"<[A-Z][a-zA-Z]*\s*[^>]*/\s*>").unwrap();
    result = self_closing_re.replace_all(&result, "").to_string();

    // Strip unknown block-level JSX tags but keep content
    // Handle common JSX tags individually since regex doesn't support backreferences
    let jsx_tags = [
        "Frame",
        "Card",
        "Cards",
        "Steps",
        "Step",
        "Tabs",
        "Tab",
        "ResponseField",
        "ParamField",
        "Expandable",
    ];
    for tag in jsx_tags {
        let pattern = format!(r"(?s)<{tag}[^>]*>\s*(.*?)\s*</{tag}>");
        if let Ok(re) = Regex::new(&pattern) {
            result = re
                .replace_all(&result, |caps: &regex::Captures| caps[1].to_string())
                .to_string();
        }
    }

    // Clean up excessive blank lines
    let multi_blank_re = Regex::new(r"\n{3,}").unwrap();
    result = multi_blank_re.replace_all(&result, "\n\n").to_string();

    result.trim().to_string()
}

struct SectionData {
    page_slug: String,
    section_id: String,
    title: String,
    level: u8,
    start: usize,
    end: usize,
}

fn extract_sections(page_slug: &str, markdown: &str) -> Vec<SectionData> {
    let heading_re = Regex::new(r"(?m)^(#{1,4})\s+(.+)$").unwrap();

    let mut headings: Vec<(usize, u8, String, usize)> = Vec::new(); // (byte_start, level, title, line_start)

    for cap in heading_re.captures_iter(markdown) {
        let full_match = cap.get(0).unwrap();
        let start = full_match.start();

        // Skip headings inside code blocks
        // Count the number of ``` before this position
        let before = &markdown[..start];
        let fence_count = before.matches("```").count();
        if fence_count % 2 == 1 {
            // We're inside a code block, skip this "heading"
            continue;
        }

        let level = cap[1].len() as u8;
        let title = cap[2].trim().to_string();
        headings.push((start, level, title, start));
    }

    let mut sections = Vec::new();

    for (i, (start, level, title, _)) in headings.iter().enumerate() {
        // Find end: next heading with level <= this one, or EOF
        let end = headings
            .iter()
            .skip(i + 1)
            .find(|(_, l, _, _)| *l <= *level)
            .map(|(s, _, _, _)| *s)
            .unwrap_or(markdown.len());

        let section_id = slugify(title);

        sections.push(SectionData {
            page_slug: page_slug.to_string(),
            section_id,
            title: title.clone(),
            level: *level,
            start: *start,
            end,
        });
    }

    sections
}

fn slugify(s: &str) -> String {
    s.chars()
        .map(|c| {
            if c.is_alphanumeric() {
                c.to_ascii_lowercase()
            } else {
                '-'
            }
        })
        .collect::<String>()
        .split('-')
        .filter(|s| !s.is_empty())
        .collect::<Vec<_>>()
        .join("-")
}
